import pandas as pd
import requests
import csv
import numpy as np
from bs4 import BeautifulSoup
import json # library to handle JSON files
from geopy.geocoders import Nominatim # convert an address into latitude and longitude values
import requests # library to handle requests
from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe
# Matplotlib and associated plotting modules
import matplotlib.cm as cm
import matplotlib.colors as colors
# import k-means from clustering stage
from sklearn.cluster import KMeans

#import folium # map rendering library

res = requests.get("https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M")
soup = BeautifulSoup(res.content,'lxml')
table = soup.find_all('table')[0] 
df = pd.read_html(str(table))[0]
df.drop(df[df['Borough'] == 'Not assigned'].index , inplace=True)

df = df.reset_index(drop=True)
#print(df.columns)
sort = df.sort_values(by ='Postal code' , ascending=True)
sort = sort.reset_index(drop=True)
sort.shape

url = 'https://cocl.us/Geospatial_data'
data = pd.read_csv(url,sep=",") # use sep="," for coma separation. 
data.head()
sort2 = data.sort_values(by ='Postal Code' , ascending=True)
sort2.head(10)

lat = sort2["Latitude"]
lon = sort2["Longitude"]
sort = pd.concat([sort,lat], axis = 1)
sort = pd.concat([sort,lon], axis = 1)
sort


toronto_data = sort[sort['Borough'] == 'Downtown Toronto'].reset_index(drop=True)
# eliminate 'Postcode' column
toronto_data=toronto_data.drop(['Postal code'], axis=1)

toronto_data = toronto_data.drop_duplicates(subset='Neighborhood', keep="last")

# Delete these row indexes from dataFrame
toronto_data.drop(indexNames , inplace=True)
toronto_data = toronto_data.reset_index(drop=True)




CLIENT_ID = 'H002AVLCTRPE0XD5DXOEMVPIDZAKXTOZJ5CH5LGLVLNA0YFP' # your Foursquare ID
CLIENT_SECRET = 'ZLEEBGZOGGPKCNYEB1QYULYZBAXRC01XYDVPR4KLC2VKGUSF' # your Foursquare Secret
VERSION = '20180604'
LIMIT = 200 # limit of number of venues returned by Foursquare API
radius = 500 # define radius

def getNearbyVenues(names, latitudes, longitudes, radius=500):
    
    venues_list=[]
    for name, lat, lng in zip(names, latitudes, longitudes):
        print(name)
            
        # create the API request URL
        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(
            CLIENT_ID, 
            CLIENT_SECRET, 
            VERSION, 
            lat, 
            lng, 
            radius, 
            LIMIT)
            
        # make the GET request
        results = requests.get(url).json()["response"]['groups'][0]['items']
        
        # return only relevant information for each nearby venue
        venues_list.append([(
            name, 
            lat, 
            lng, 
            v['venue']['name'], 
            v['venue']['location']['lat'], 
            v['venue']['location']['lng'],  
            v['venue']['categories'][0]['name']) for v in results])

    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])
    nearby_venues.columns = ['Neighborhood', 
                  'Neighborhood Latitude', 
                  'Neighborhood Longitude', 
                  'Venue', 
                  'Venue Latitude', 
                  'Venue Longitude', 
                  'Venue Category']
    
    return(nearby_venues)
    
    
    
    
    
    
    
    toronto_venues = getNearbyVenues(names=toronto_data['Neighborhood'],
                                   latitudes=toronto_data['Latitude'],
                                   longitudes=toronto_data['Longitude'],
                                  )
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  
                                  

# one hot encoding
toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix="", prefix_sep="")

# add neighborhood column back to dataframe
toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] 

# move neighborhood column to the first column
fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])
toronto_onehot = toronto_onehot[fixed_columns]

toronto_onehot.head()

# Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category
toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()
toronto_grouped.head(20)
